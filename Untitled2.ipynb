{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg4I1Q5o0zBSzrekvU4lJj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Subibub/ML/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w-PYSKqASTqN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.models.detection import ssdlite320_mobilenet_v3_large\n",
        "from torchvision.models.detection.ssd import SSDClassificationHead\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "import glob\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 시드 설정\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed()"
      ],
      "metadata": {
        "id": "_XjAVd8zSYMv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Nt8v1i4Sam3",
        "outputId": "a0df5f8b-a0d6-4070-f535-d4b8032a82e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 경로 설정 (사용자 환경에 맞게 수정 필요)\n",
        "DATASET_PATH = '/content/drive/MyDrive/DL'  # 이 경로는 실제 데이터셋 위치로 변경해야 합니다\n",
        "ANNOTATIONS_FILE = os.path.join(DATASET_PATH, 'annotations.json')  # JSON 라벨 파일 경로\n",
        "IMAGES_DIR = os.path.join(DATASET_PATH, 'images')  # 이미지 폴더 경로\n"
      ],
      "metadata": {
        "id": "DsO5kKDsSdGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 설정값\n",
        "YOLO_DATASET_PATH = '/content/drive/MyDrive/DL/complete_dataset'  # YOLO 데이터셋 경로\n",
        "SSD_OUTPUT_PATH = '/content/drive/MyDrive/DL/ssd_dataset'     # 변환된 SSD 데이터셋 저장 경로\n",
        "BATCH_SIZE = 500  # 한 번에 처리할 이미지 수\n"
      ],
      "metadata": {
        "id": "4xjiOSUfS8jZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 디렉토리 생성\n",
        "os.makedirs(os.path.join(SSD_OUTPUT_PATH, 'images'), exist_ok=True)\n",
        "os.makedirs(os.path.join(SSD_OUTPUT_PATH, 'annotations'), exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "eu26Ql2BrHGt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLO 포맷에서 bounding box 정보 추출 함수\n",
        "def convert_yolo_to_ssd_format(yolo_file_path, image_width, image_height, class_names):\n",
        "    \"\"\"\n",
        "    YOLO 포맷 (class_id, x_center, y_center, width, height)를\n",
        "    SSD 포맷 (xmin, ymin, xmax, ymax, class_name)으로 변환\n",
        "    \"\"\"\n",
        "    boxes = []\n",
        "\n",
        "    with open(yolo_file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        class_id = int(parts[0])\n",
        "        x_center = float(parts[1]) * image_width\n",
        "        y_center = float(parts[2]) * image_height\n",
        "        width = float(parts[3]) * image_width\n",
        "        height = float(parts[4]) * image_height\n",
        "\n",
        "        # 바운딩 박스 좌표 계산 (SSD 포맷)\n",
        "        xmin = max(0, int(x_center - width / 2))\n",
        "        ymin = max(0, int(y_center - height / 2))\n",
        "        xmax = min(image_width, int(x_center + width / 2))\n",
        "        ymax = min(image_height, int(y_center + height / 2))\n",
        "\n",
        "        class_name = class_names[class_id]\n",
        "        boxes.append((xmin, ymin, xmax, ymax, class_name))\n",
        "\n",
        "    return boxes\n"
      ],
      "metadata": {
        "id": "GDY74yybrOR_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pascal VOC XML 파일 생성 함수\n",
        "def create_pascal_voc_xml(image_path, boxes, image_width, image_height, output_path):\n",
        "    \"\"\"\n",
        "    바운딩 박스 정보를 이용해 Pascal VOC XML 포맷으로 변환\n",
        "    \"\"\"\n",
        "    root = ET.Element(\"annotation\")\n",
        "\n",
        "    folder = ET.SubElement(root, \"folder\")\n",
        "    folder.text = \"images\"\n",
        "\n",
        "    filename_elem = ET.SubElement(root, \"filename\")\n",
        "    filename_elem.text = os.path.basename(image_path)\n",
        "\n",
        "    path_elem = ET.SubElement(root, \"path\")\n",
        "    path_elem.text = image_path\n",
        "\n",
        "    source = ET.SubElement(root, \"source\")\n",
        "    database = ET.SubElement(source, \"database\")\n",
        "    database.text = \"Unknown\"\n",
        "\n",
        "    size = ET.SubElement(root, \"size\")\n",
        "    width_elem = ET.SubElement(size, \"width\")\n",
        "    width_elem.text = str(image_width)\n",
        "    height_elem = ET.SubElement(size, \"height\")\n",
        "    height_elem.text = str(image_height)\n",
        "    depth = ET.SubElement(size, \"depth\")\n",
        "    depth.text = \"3\"\n",
        "\n",
        "    segmented = ET.SubElement(root, \"segmented\")\n",
        "    segmented.text = \"0\"\n",
        "\n",
        "    for box in boxes:\n",
        "        xmin, ymin, xmax, ymax, class_name = box\n",
        "\n",
        "        object_elem = ET.SubElement(root, \"object\")\n",
        "        name = ET.SubElement(object_elem, \"name\")\n",
        "        name.text = class_name\n",
        "\n",
        "        pose = ET.SubElement(object_elem, \"pose\")\n",
        "        pose.text = \"Unspecified\"\n",
        "\n",
        "        truncated = ET.SubElement(object_elem, \"truncated\")\n",
        "        truncated.text = \"0\"\n",
        "\n",
        "        difficult = ET.SubElement(object_elem, \"difficult\")\n",
        "        difficult.text = \"0\"\n",
        "\n",
        "        bndbox = ET.SubElement(object_elem, \"bndbox\")\n",
        "        xmin_elem = ET.SubElement(bndbox, \"xmin\")\n",
        "        xmin_elem.text = str(xmin)\n",
        "        ymin_elem = ET.SubElement(bndbox, \"ymin\")\n",
        "        ymin_elem.text = str(ymin)\n",
        "        xmax_elem = ET.SubElement(bndbox, \"xmax\")\n",
        "        xmax_elem.text = str(xmax)\n",
        "        ymax_elem = ET.SubElement(bndbox, \"ymax\")\n",
        "        ymax_elem.text = str(ymax)\n",
        "\n",
        "    # XML 파일 저장\n",
        "    xml_str = minidom.parseString(ET.tostring(root)).toprettyxml(indent=\"  \")\n",
        "    with open(output_path, \"w\") as f:\n",
        "        f.write(xml_str)\n"
      ],
      "metadata": {
        "id": "PngiamCfrPgJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TFRecord 파일 생성 함수\n",
        "def create_tf_example(image_path, xml_path):\n",
        "    \"\"\"\n",
        "    이미지와 XML 파일로부터 TFRecord example 생성\n",
        "    \"\"\"\n",
        "    with tf.io.gfile.GFile(image_path, 'rb') as fid:\n",
        "        encoded_image = fid.read()\n",
        "\n",
        "    # XML 파일에서 annotation 정보 파싱\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    size = root.find('size')\n",
        "    width = int(size.find('width').text)\n",
        "    height = int(size.find('height').text)\n",
        "\n",
        "    xmins = []\n",
        "    ymins = []\n",
        "    xmaxs = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text\n",
        "        class_id = class_names.index(class_name)\n",
        "\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = float(bbox.find('xmin').text) / width\n",
        "        ymin = float(bbox.find('ymin').text) / height\n",
        "        xmax = float(bbox.find('xmax').text) / width\n",
        "        ymax = float(bbox.find('ymax').text) / height\n",
        "\n",
        "        xmins.append(xmin)\n",
        "        ymins.append(ymin)\n",
        "        xmaxs.append(xmax)\n",
        "        ymaxs.append(ymax)\n",
        "        classes_text.append(class_name.encode('utf8'))\n",
        "        classes.append(class_id)\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
        "        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
        "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[os.path.basename(image_path).encode('utf8')])),\n",
        "        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[os.path.basename(image_path).encode('utf8')])),\n",
        "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_image])),\n",
        "        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=['jpeg'.encode('utf8')])),\n",
        "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmins)),\n",
        "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmaxs)),\n",
        "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymins)),\n",
        "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymaxs)),\n",
        "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
        "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n",
        "    }))\n",
        "\n",
        "    return tf_example\n"
      ],
      "metadata": {
        "id": "l6-y6BcqrTPw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 이름 로드 (classes.txt 파일에서 로드한다고 가정)\n",
        "class_names = []\n",
        "with open(os.path.join(YOLO_DATASET_PATH, 'classes.txt'), 'r') as f:\n",
        "    class_names = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# 라벨맵 파일 생성\n",
        "def create_label_map(class_names, output_path):\n",
        "    with open(output_path, 'w') as f:\n",
        "        for i, name in enumerate(class_names):\n",
        "            f.write('item {\\n')\n",
        "            f.write(f'  id: {i+1}\\n')\n",
        "            f.write(f'  name: \"{name}\"\\n')\n",
        "            f.write('}\\n')\n",
        "\n",
        "# 라벨맵 생성\n",
        "create_label_map(class_names, os.path.join(SSD_OUTPUT_PATH, 'label_map.pbtxt'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "Qt7poNQNrYI-",
        "outputId": "955c5bf7-db3e-4cf5-f77d-020b0715b555"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/DL/complete_dataset/classes.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7138b99b34c4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 클래스 이름 로드 (classes.txt 파일에서 로드한다고 가정)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYOLO_DATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classes.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/DL/complete_dataset/classes.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 분할 처리\n",
        "def process_dataset_in_batches():\n",
        "    # 모든 이미지 파일 경로 가져오기\n",
        "    image_paths = glob.glob(os.path.join(YOLO_DATASET_PATH, 'images', '*.jpg'))\n",
        "    image_paths.extend(glob.glob(os.path.join(YOLO_DATASET_PATH, 'images', '*.jpeg')))\n",
        "    image_paths.extend(glob.glob(os.path.join(YOLO_DATASET_PATH, 'images', '*.png')))\n",
        "\n",
        "    total_images = len(image_paths)\n",
        "    print(f\"총 {total_images}개의 이미지를 처리합니다.\")\n",
        "\n",
        "    # TFRecord 파일 준비\n",
        "    train_writer = tf.io.TFRecordWriter(os.path.join(SSD_OUTPUT_PATH, 'train.record'))\n",
        "    val_writer = tf.io.TFRecordWriter(os.path.join(SSD_OUTPUT_PATH, 'val.record'))\n",
        "\n",
        "    # 학습/검증 데이터 분할 (80:20)\n",
        "    np.random.shuffle(image_paths)\n",
        "    split_idx = int(total_images * 0.8)\n",
        "    train_images = image_paths[:split_idx]\n",
        "    val_images = image_paths[split_idx:]\n",
        "\n",
        "    # 학습 데이터 처리\n",
        "    for batch_start in range(0, len(train_images), BATCH_SIZE):\n",
        "        batch_paths = train_images[batch_start:batch_start + BATCH_SIZE]\n",
        "        process_batch(batch_paths, train_writer, is_training=True)\n",
        "\n",
        "    # 검증 데이터 처리\n",
        "    for batch_start in range(0, len(val_images), BATCH_SIZE):\n",
        "        batch_paths = val_images[batch_start:batch_start + BATCH_SIZE]\n",
        "        process_batch(batch_paths, val_writer, is_training=False)\n",
        "\n",
        "    train_writer.close()\n",
        "    val_writer.close()\n"
      ],
      "metadata": {
        "id": "HCW7hYaaru8a"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 배치 단위 처리 함수\n",
        "def process_batch(image_paths, tf_writer, is_training=True):\n",
        "    dataset_type = \"train\" if is_training else \"val\"\n",
        "\n",
        "    for img_path in tqdm(image_paths, desc=f\"Processing {dataset_type} batch\"):\n",
        "        try:\n",
        "            # 이미지 로드 및 크기 확인\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                print(f\"이미지를 로드할 수 없습니다: {img_path}\")\n",
        "                continue\n",
        "\n",
        "            height, width, _ = img.shape\n",
        "\n",
        "            # YOLO 형식 레이블 파일 경로\n",
        "            base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "            label_path = os.path.join(YOLO_DATASET_PATH, 'labels', f\"{base_name}.txt\")\n",
        "\n",
        "            if not os.path.exists(label_path):\n",
        "                print(f\"레이블 파일이 없습니다: {label_path}\")\n",
        "                continue\n",
        "\n",
        "            # YOLO에서 SSD 형식으로 변환\n",
        "            boxes = convert_yolo_to_ssd_format(label_path, width, height, class_names)\n",
        "\n",
        "            # 이미지를 SSD 데이터셋 디렉토리로 복사\n",
        "            dst_img_path = os.path.join(SSD_OUTPUT_PATH, 'images', f\"{base_name}.jpg\")\n",
        "            cv2.imwrite(dst_img_path, img)\n",
        "\n",
        "            # VOC XML 파일 생성\n",
        "            xml_path = os.path.join(SSD_OUTPUT_PATH, 'annotations', f\"{base_name}.xml\")\n",
        "            create_pascal_voc_xml(dst_img_path, boxes, width, height, xml_path)\n",
        "\n",
        "            # TFRecord에 추가\n",
        "            tf_example = create_tf_example(dst_img_path, xml_path)\n",
        "            tf_writer.write(tf_example.SerializeToString())\n",
        "\n",
        "            # 메모리 정리\n",
        "            del img, boxes, tf_example\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"오류 발생 ({img_path}): {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # 메모리 정리\n",
        "    import gc\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "xHssaNukr0u-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MobileNet + SSD 모델 학습 함수\n",
        "def train_mobilenet_ssd():\n",
        "    # 필요한 TensorFlow Object Detection API 설치\n",
        "    if not os.path.exists('/content/models'):\n",
        "        !git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "    # Protobuf 설치 및 컴파일\n",
        "    !apt-get install -qq protobuf-compiler\n",
        "    !cd /content/models/research && protoc object_detection/protos/*.proto --python_out=.\n",
        "    !cd /content/models/research && pip install -q .\n",
        "\n",
        "    # 모델 설정 파일 생성\n",
        "    config_text = \"\"\"\n",
        "    model {\n",
        "      ssd {\n",
        "        num_classes: %NUM_CLASSES%\n",
        "        image_resizer {\n",
        "          fixed_shape_resizer {\n",
        "            height: 300\n",
        "            width: 300\n",
        "          }\n",
        "        }\n",
        "        feature_extractor {\n",
        "          type: \"ssd_mobilenet_v2\"\n",
        "          depth_multiplier: 1.0\n",
        "          min_depth: 16\n",
        "          conv_hyperparams {\n",
        "            regularizer {\n",
        "              l2_regularizer {\n",
        "                weight: 4.0e-05\n",
        "              }\n",
        "            }\n",
        "            initializer {\n",
        "              truncated_normal_initializer {\n",
        "                mean: 0.0\n",
        "                stddev: 0.03\n",
        "              }\n",
        "            }\n",
        "            activation: RELU_6\n",
        "            batch_norm {\n",
        "              decay: 0.9997\n",
        "              center: true\n",
        "              scale: true\n",
        "              epsilon: 0.001\n",
        "              train: true\n",
        "            }\n",
        "          }\n",
        "          override_base_feature_extractor_hyperparams: true\n",
        "        }\n",
        "        box_coder {\n",
        "          faster_rcnn_box_coder {\n",
        "            y_scale: 10.0\n",
        "            x_scale: 10.0\n",
        "            height_scale: 5.0\n",
        "            width_scale: 5.0\n",
        "          }\n",
        "        }\n",
        "        matcher {\n",
        "          argmax_matcher {\n",
        "            matched_threshold: 0.5\n",
        "            unmatched_threshold: 0.5\n",
        "            ignore_thresholds: false\n",
        "            negatives_lower_than_unmatched: true\n",
        "            force_match_for_each_row: true\n",
        "          }\n",
        "        }\n",
        "        similarity_calculator {\n",
        "          iou_similarity {\n",
        "          }\n",
        "        }\n",
        "        box_predictor {\n",
        "          convolutional_box_predictor {\n",
        "            conv_hyperparams {\n",
        "              regularizer {\n",
        "                l2_regularizer {\n",
        "                  weight: 4.0e-05\n",
        "                }\n",
        "              }\n",
        "              initializer {\n",
        "                truncated_normal_initializer {\n",
        "                  mean: 0.0\n",
        "                  stddev: 0.03\n",
        "                }\n",
        "              }\n",
        "              activation: RELU_6\n",
        "              batch_norm {\n",
        "                decay: 0.9997\n",
        "                center: true\n",
        "                scale: true\n",
        "                epsilon: 0.001\n",
        "                train: true\n",
        "              }\n",
        "            }\n",
        "            min_depth: 0\n",
        "            max_depth: 0\n",
        "            num_layers_before_predictor: 0\n",
        "            use_dropout: false\n",
        "            dropout_keep_probability: 0.8\n",
        "            kernel_size: 3\n",
        "            box_code_size: 4\n",
        "            apply_sigmoid_to_scores: false\n",
        "          }\n",
        "        }\n",
        "        anchor_generator {\n",
        "          ssd_anchor_generator {\n",
        "            num_layers: 6\n",
        "            min_scale: 0.2\n",
        "            max_scale: 0.95\n",
        "            aspect_ratios: 1.0\n",
        "            aspect_ratios: 2.0\n",
        "            aspect_ratios: 0.5\n",
        "            aspect_ratios: 3.0\n",
        "            aspect_ratios: 0.3333\n",
        "          }\n",
        "        }\n",
        "        post_processing {\n",
        "          batch_non_max_suppression {\n",
        "            score_threshold: 1.0e-08\n",
        "            iou_threshold: 0.6\n",
        "            max_detections_per_class: 100\n",
        "            max_total_detections: 100\n",
        "          }\n",
        "          score_converter: SIGMOID\n",
        "        }\n",
        "        normalize_loss_by_num_matches: true\n",
        "        loss {\n",
        "          localization_loss {\n",
        "            weighted_smooth_l1 {\n",
        "            }\n",
        "          }\n",
        "          classification_loss {\n",
        "            weighted_sigmoid_focal {\n",
        "              gamma: 2.0\n",
        "              alpha: 0.75\n",
        "            }\n",
        "          }\n",
        "          hard_example_miner {\n",
        "            num_hard_examples: 3000\n",
        "            iou_threshold: 0.99\n",
        "            loss_type: CLASSIFICATION\n",
        "            max_negatives_per_positive: 3\n",
        "            min_negatives_per_image: 3\n",
        "          }\n",
        "          classification_weight: 1.0\n",
        "          localization_weight: 1.0\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    train_config {\n",
        "      batch_size: 8\n",
        "      data_augmentation_options {\n",
        "        random_horizontal_flip {\n",
        "        }\n",
        "      }\n",
        "      data_augmentation_options {\n",
        "        random_crop_image {\n",
        "          min_object_covered: 0.0\n",
        "          min_aspect_ratio: 0.75\n",
        "          max_aspect_ratio: 3.0\n",
        "          min_area: 0.75\n",
        "          max_area: 1.0\n",
        "          overlap_thresh: 0.0\n",
        "        }\n",
        "      }\n",
        "      optimizer {\n",
        "        momentum_optimizer {\n",
        "          learning_rate {\n",
        "            cosine_decay_learning_rate {\n",
        "              learning_rate_base: 0.0799999982119\n",
        "              total_steps: 50000\n",
        "              warmup_learning_rate: 0.0266660004854\n",
        "              warmup_steps: 1000\n",
        "            }\n",
        "          }\n",
        "          momentum_optimizer_value: 0.9\n",
        "        }\n",
        "        use_moving_average: false\n",
        "      }\n",
        "      fine_tune_checkpoint: \"/content/models/research/object_detection/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt\"\n",
        "      fine_tune_checkpoint_type: \"detection\"\n",
        "      num_steps: 50000\n",
        "    }\n",
        "    train_input_reader {\n",
        "      label_map_path: \"%LABEL_MAP_PATH%\"\n",
        "      tf_record_input_reader {\n",
        "        input_path: \"%TRAIN_RECORD_PATH%\"\n",
        "      }\n",
        "    }\n",
        "    eval_config {\n",
        "      num_examples: 8000\n",
        "      metrics_set: \"coco_detection_metrics\"\n",
        "      use_moving_averages: false\n",
        "    }\n",
        "    eval_input_reader {\n",
        "      label_map_path: \"%LABEL_MAP_PATH%\"\n",
        "      shuffle: false\n",
        "      num_readers: 1\n",
        "      tf_record_input_reader {\n",
        "        input_path: \"%VAL_RECORD_PATH%\"\n",
        "      }\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # 설정 파일에 경로 및 클래스 수 대체\n",
        "    config_text = config_text.replace(\"%NUM_CLASSES%\", str(len(class_names)))\n",
        "    config_text = config_text.replace(\"%LABEL_MAP_PATH%\", os.path.join(SSD_OUTPUT_PATH, 'label_map.pbtxt'))\n",
        "    config_text = config_text.replace(\"%TRAIN_RECORD_PATH%\", os.path.join(SSD_OUTPUT_PATH, 'train.record'))\n",
        "    config_text = config_text.replace(\"%VAL_RECORD_PATH%\", os.path.join(SSD_OUTPUT_PATH, 'val.record'))\n",
        "\n",
        "    config_path = os.path.join(SSD_OUTPUT_PATH, 'pipeline.config')\n",
        "    with open(config_path, 'w') as f:\n",
        "        f.write(config_text)\n",
        "\n",
        "    # 사전 훈련된 MobileNet+SSD 모델 다운로드\n",
        "    !wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
        "    !tar -xzf ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
        "\n",
        "    # 모델 훈련\n",
        "    !python /content/models/research/object_detection/model_main.py \\\n",
        "      --pipeline_config_path={config_path} \\\n",
        "      --model_dir={os.path.join(SSD_OUTPUT_PATH, 'model')} \\\n",
        "      --alsologtostderr\n",
        "\n",
        "# 변환 및 훈련 실행\n",
        "if __name__ == \"__main__\":\n",
        "    # 데이터셋 변환\n",
        "    process_dataset_in_batches()\n",
        "\n",
        "    # 모델 훈련\n",
        "    train_mobilenet_ssd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjNMlrOyr6eu",
        "outputId": "92374b5d-9598-44a0-e840-040fce04d5a0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 0개의 이미지를 처리합니다.\n",
            "\u001b[31mERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m--2025-03-31 05:33:20--  http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.167.207, 172.253.115.207, 172.253.122.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.167.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 187925923 (179M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_coco_2018_03_29.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_co 100%[===================>] 179.22M   131MB/s    in 1.4s    \n",
            "\n",
            "2025-03-31 05:33:21 (131 MB/s) - ‘ssd_mobilenet_v2_coco_2018_03_29.tar.gz’ saved [187925923/187925923]\n",
            "\n",
            "2025-03-31 05:33:25.272810: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743399205.295565   27995 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743399205.302310   27995 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/model_main.py\", line 24, in <module>\n",
            "    from tensorflow.compat.v1 import estimator as tf_estimator\n",
            "ImportError: cannot import name 'estimator' from 'tensorflow.compat.v1' (/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 행동 카테고리 정의 (실제 데이터셋에 맞게 수정 필요)\n",
        "ACTION_CATEGORIES = {\n",
        "    1: \"walking\",\n",
        "    2: \"running\",\n",
        "    3: \"sitting\",\n",
        "    4: \"standing\"\n",
        "}"
      ],
      "metadata": {
        "id": "5IXFDabgSe3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COCO 형식 데이터셋을 위한 커스텀 데이터셋 클래스\n",
        "class ActionDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None):\n",
        "        self.coco = COCO(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 이미지 ID로 이미지 로드\n",
        "        img_id = self.ids[idx]\n",
        "        img_info = self.coco.loadImgs(img_id)[0]\n",
        "        img_path = os.path.join(self.img_dir, img_info['file_name'])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # 어노테이션 정보 가져오기\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
        "        anns = self.coco.loadAnns(ann_ids)\n",
        "\n",
        "        # 바운딩 박스와 라벨 정보 추출\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        for ann in anns:\n",
        "            # COCO 형식의 바운딩 박스를 [x_min, y_min, x_max, y_max] 형식으로 변환\n",
        "            x_min = ann['bbox'][0]\n",
        "            y_min = ann['bbox'][1]\n",
        "            width = ann['bbox'][2]\n",
        "            height = ann['bbox'][3]\n",
        "            x_max = x_min + width\n",
        "            y_max = y_min + height\n",
        "\n",
        "            # 이미지 경계 확인\n",
        "            img_width, img_height = img.size\n",
        "            x_min = max(0, x_min)\n",
        "            y_min = max(0, y_min)\n",
        "            x_max = min(img_width, x_max)\n",
        "            y_max = min(img_height, y_max)\n",
        "\n",
        "            # 유효한 바운딩 박스인지 확인\n",
        "            if x_max > x_min and y_max > y_min:\n",
        "                boxes.append([x_min, y_min, x_max, y_max])\n",
        "                labels.append(ann['category_id'])\n",
        "\n",
        "        # 이미지 변환\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # 타겟 딕셔너리 생성\n",
        "        target = {}\n",
        "        if len(boxes) > 0:\n",
        "            target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        else:\n",
        "            # 바운딩 박스가 없는 경우 더미 박스 생성\n",
        "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.zeros((0), dtype=torch.int64)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n"
      ],
      "metadata": {
        "id": "7sQ7iEsdSiH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "def get_transform():\n",
        "    transforms_list = [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]\n",
        "    return transforms.Compose(transforms_list)\n",
        "\n",
        "# 모델 준비\n",
        "def get_model(num_classes):\n",
        "    # MobileNet + SSD 모델 로드 (사전 학습된 가중치 사용)\n",
        "    model = ssdlite320_mobilenet_v3_large(pretrained=True)\n",
        "\n",
        "    # 클래스 수 변경 (배경 클래스 포함)\n",
        "    in_channels = model.head.classification_head.in_channels\n",
        "    num_anchors = model.head.classification_head.num_anchors\n",
        "\n",
        "    # 새로운 분류 헤드 생성\n",
        "    model.head.classification_head = SSDClassificationHead(\n",
        "        in_channels, num_anchors, num_classes + 1  # 배경 클래스 포함\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "i-dxRR9PSkIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_one_epoch(model, optimizer, data_loader, device):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for images, targets in data_loader:\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += losses.item()\n",
        "\n",
        "    return total_loss / len(data_loader)\n"
      ],
      "metadata": {
        "id": "d9HRGabgSlvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가 함수\n",
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    ground_truths = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in data_loader:\n",
        "            images = list(img.to(device) for img in images)\n",
        "\n",
        "            outputs = model(images)\n",
        "\n",
        "            for i, output in enumerate(outputs):\n",
        "                pred_boxes = output['boxes'].cpu().numpy()\n",
        "                pred_scores = output['scores'].cpu().numpy()\n",
        "                pred_labels = output['labels'].cpu().numpy()\n",
        "\n",
        "                gt_boxes = targets[i]['boxes'].cpu().numpy()\n",
        "                gt_labels = targets[i]['labels'].cpu().numpy()\n",
        "\n",
        "                predictions.append({\n",
        "                    'boxes': pred_boxes,\n",
        "                    'scores': pred_scores,\n",
        "                    'labels': pred_labels\n",
        "                })\n",
        "\n",
        "                ground_truths.append({\n",
        "                    'boxes': gt_boxes,\n",
        "                    'labels': gt_labels\n",
        "                })\n",
        "\n",
        "    # 간단한 mAP 계산 (실제로는 pycocotools.cocoeval 사용 권장)\n",
        "    # 이 예제에서는 간단한 구현만 포함합니다\n",
        "    return predictions, ground_truths"
      ],
      "metadata": {
        "id": "epFDoRXQSnZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화 함수\n",
        "def visualize_prediction(image, prediction, threshold=0.5):\n",
        "    # PIL 이미지로 변환\n",
        "    image = image.permute(1, 2, 0).cpu().numpy()\n",
        "    image = (image * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]) * 255\n",
        "    image = image.astype(np.uint8)\n",
        "    image = Image.fromarray(image)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    boxes = prediction['boxes'].cpu().numpy()\n",
        "    scores = prediction['scores'].cpu().numpy()\n",
        "    labels = prediction['labels'].cpu().numpy()\n",
        "\n",
        "    # 임계값보다 높은 신뢰도를 가진 예측만 시각화\n",
        "    for box, score, label in zip(boxes, scores, labels):\n",
        "        if score >= threshold:\n",
        "            x_min, y_min, x_max, y_max = box\n",
        "            draw.rectangle([(x_min, y_min), (x_max, y_max)], outline=\"red\", width=2)\n",
        "\n",
        "            # 라벨과 신뢰도 표시\n",
        "            label_text = f\"{ACTION_CATEGORIES.get(label, 'unknown')}: {score:.2f}\"\n",
        "            draw.text((x_min, y_min - 10), label_text, fill=\"red\")\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "TzRhZeT3SpLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 메인 함수\n",
        "def main():\n",
        "    # GPU 사용 가능 여부 확인\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # 데이터셋 및 데이터로더 생성\n",
        "    try:\n",
        "        dataset = ActionDataset(ANNOTATIONS_FILE, IMAGES_DIR, transform=get_transform())\n",
        "\n",
        "        # 데이터셋 분할 (학습:검증 = 8:2)\n",
        "        dataset_size = len(dataset)\n",
        "        train_size = int(0.8 * dataset_size)\n",
        "        val_size = dataset_size - train_size\n",
        "\n",
        "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        # 데이터 로더 생성\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x))\n",
        "        )\n",
        "\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x))\n",
        "        )\n",
        "\n",
        "        print(f\"Training samples: {len(train_dataset)}\")\n",
        "        print(f\"Validation samples: {len(val_dataset)}\")\n",
        "\n",
        "        # 모델 생성\n",
        "        num_classes = len(ACTION_CATEGORIES)\n",
        "        model = get_model(num_classes)\n",
        "        model.to(device)\n",
        "\n",
        "        # 옵티마이저 및 학습률 스케줄러 설정\n",
        "        params = [p for p in model.parameters() if p.requires_grad]\n",
        "        optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "        # 학습 실행\n",
        "        num_epochs = 10\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "            # 학습\n",
        "            start_time = time.time()\n",
        "            train_loss = train_one_epoch(model, optimizer, train_loader, device)\n",
        "            end_time = time.time()\n",
        "\n",
        "            print(f\"Train Loss: {train_loss:.4f}, Time: {end_time - start_time:.2f}s\")\n",
        "\n",
        "            # 평가\n",
        "            predictions, ground_truths = evaluate(model, val_loader, device)\n",
        "\n",
        "            # 학습률 업데이트\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            # 모델 저장\n",
        "            if (epoch + 1) % 5 == 0:\n",
        "                torch.save(model.state_dict(), f\"mobilenet_ssd_action_epoch{epoch+1}.pth\")\n",
        "                print(f\"Model saved at epoch {epoch+1}\")\n",
        "\n",
        "        # 최종 모델 저장\n",
        "        torch.save(model.state_dict(), \"mobilenet_ssd_action_final.pth\")\n",
        "        print(\"Final model saved\")\n",
        "\n",
        "        # 테스트 이미지에 대한 예측 시각화 (샘플)\n",
        "        if len(val_dataset) > 0:\n",
        "            image, target = val_dataset[0]\n",
        "            image_tensor = image.unsqueeze(0).to(device)\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                prediction = model(image_tensor)[0]\n",
        "\n",
        "            # 결과 시각화\n",
        "            result_image = visualize_prediction(image, prediction)\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.imshow(result_image)\n",
        "            plt.axis('off')\n",
        "            plt.savefig('prediction_result.png')\n",
        "            plt.show()\n",
        "\n",
        "            print(\"Prediction visualization saved as 'prediction_result.png'\")\n",
        "\n",
        "        # 다른 모델과 비교 (YOLO, ResNet50)\n",
        "        print(\"\\n=== Model Comparison ===\")\n",
        "        print(\"1. MobileNet-SSD:\")\n",
        "        print(\"   - 정확도: 적절한 수준\")\n",
        "        print(\"   - 처리속도: 빠름 (모바일 디바이스에 최적화)\")\n",
        "        print(\"   - 모델 크기: 작음 (~20MB)\")\n",
        "        print(\"   - 실용성: 실시간 처리에 적합, 리소스 제약 환경에서 효율적\")\n",
        "\n",
        "        print(\"\\n2. YOLO (참고):\")\n",
        "        print(\"   - 정확도: 높음\")\n",
        "        print(\"   - 처리속도: 매우 빠름\")\n",
        "        print(\"   - 모델 크기: 중간 (~50-250MB, 버전에 따라 다름)\")\n",
        "        print(\"   - 실용성: 실시간 처리에 매우 적합, 고성능 GPU에서 최적 성능\")\n",
        "\n",
        "        print(\"\\n3. ResNet50-FPN (참고):\")\n",
        "        print(\"   - 정확도: 매우 높음\")\n",
        "        print(\"   - 처리속도: 느림\")\n",
        "        print(\"   - 모델 크기: 큼 (~100MB 이상)\")\n",
        "        print(\"   - 실용성: 높은 정확도가 필요하고 속도가 중요하지 않은 경우 적합\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "ldmRw0ZZSv68"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}